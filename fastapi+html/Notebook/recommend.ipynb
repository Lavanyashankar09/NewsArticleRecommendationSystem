{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd71e378",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "# Below libraries are for text processing using NLTK\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Below libraries are for feature representation using sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Below libraries are for similarity matrices using sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity  \n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cc57354",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_articles = pd.read_csv(\"/Users/lavanya/Downloads/NewsArticleRecommendationSystem-main/new/Data/news_article.txt\")\n",
    "news_articles.to_csv(\"/Users/lavanya/Downloads/NewsArticleRecommendationSystem-main/new/Data/news_article.csv\", index=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80a7fbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>An Education While Incarcerated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Is There a Smoking Gun in the January 6th Inve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Year in Climate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kirsten Dunst’s Feminine Urges</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rebelling Against the Word Processor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            headline\n",
       "0                    An Education While Incarcerated\n",
       "1  Is There a Smoking Gun in the January 6th Inve...\n",
       "2                                The Year in Climate\n",
       "3                     Kirsten Dunst’s Feminine Urges\n",
       "4               Rebelling Against the Word Processor"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6077756",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_articles_temp = news_articles.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "252f2762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "for i in range(len(news_articles_temp[\"headline\"])):\n",
    "    string = \"\"\n",
    "    for word in news_articles_temp[\"headline\"][i].split():\n",
    "        word = (\"\".join(e for e in word if e.isalnum()))\n",
    "        word = word.lower()\n",
    "        if not word in stop_words:\n",
    "          string += word + \" \"  \n",
    "    if(i%1000==0):\n",
    "      print(i)           # To track number of records processed\n",
    "    news_articles_temp.at[i,\"headline\"] = string.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9e56b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "for i in range(len(news_articles_temp[\"headline\"])):\n",
    "    string = \"\"\n",
    "    for w in word_tokenize(news_articles_temp[\"headline\"][i]):\n",
    "        string += lemmatizer.lemmatize(w,pos = \"v\") + \" \"\n",
    "    news_articles_temp.at[i, \"headline\"] = string.strip()\n",
    "    if(i%1000==0):\n",
    "        print(i)           # To track number of records processed\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd812327",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_headline_vectorizer = TfidfVectorizer()  # default min_df=1\n",
    "tfidf_headline_features = tfidf_headline_vectorizer.fit_transform(news_articles_temp['headline'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b5fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(new):\n",
    "    recommend_news = [] \n",
    "    row_index = news_articles[news_articles['headline'] == new].index[0]\n",
    "    couple_dist = pairwise_distances(tfidf_headline_features,tfidf_headline_features[row_index])\n",
    "    indices = np.argsort(couple_dist.ravel())[0:3]\n",
    "    recommend_news.append(news_articles['headline'][indices])\n",
    "    return (recommend_news)\n",
    "recommend_news = recommend(\"A Sibling’s Wedding Toast\")\n",
    "print(recommend_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e31d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29                            A Sibling’s Wedding Toast\n",
      "27                    Ringing in the New Year (on Zoom)\n",
      "26    Hannity Says Swearing to Tell the Truth Would ...\n",
      "Name: headline, dtype: object]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844e53d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(news_articles,open('/Users/lavanya/Downloads/NewsArticleRecommendationSystem-main/new/Pickle/news_articles_list.pkl','wb'))\n",
    "pickle.dump(tfidf_headline_features,open('/Users/lavanya/Downloads/NewsArticleRecommendationSystem-main/new/Pickle/similarity.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4b00ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77717071-e3fd-4d6f-84ae-c599a80ae4f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
